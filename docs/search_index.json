[["index.html", "Time Series Analysis Chapter 1 About", " Time Series Analysis shang-chieh0830 2023-03-08 Chapter 1 About This book is a concise lecture note about Time Series Analysis. The content of this book is from the course Time Series Analysis taught by Chris Bilder. You can check his YouTube channel to get full(and correct) information about this course. Again, I do NOT own the content of this book. I write this book only for studying. All credits belong to Chris Bilder. If there is any copyright concerns, I will make this book private ASAP. "],["introduction-to-r.html", "Chapter 2 Introduction to R 2.1 Basic Operation 2.2 Vectors 2.3 Files 2.4 Regression 2.5 Object-Oriented Language", " Chapter 2 Introduction to R We will go over some of the basic R operations in this chapter. If you have questions, you should check Chris Bilder’s website for full information. 2.1 Basic Operation 2+2 #&gt; [1] 4 2^3 #&gt; [1] 8 # calculate the cdf of std. normal pnorm(1.96) # 1.96 is the quantile #&gt; [1] 0.9750021 log(1) #&gt; [1] 0 sin(pi/2) #&gt; [1] 1 3/4 #&gt; [1] 0.75 save &lt;- 2+2 save #&gt; [1] 4 objects() #&gt; [1] &quot;save&quot; ls() #&gt; [1] &quot;save&quot; # quit operaiton # q() 2.2 Vectors x &lt;- c(1,2,3,4,5) x #&gt; [1] 1 2 3 4 5 sd(x) #&gt; [1] 1.581139 mysd &lt;- function(x){ cat(&quot; My data \\n&quot;, x, &quot;\\n has std deviation&quot;,sqrt(var(x))) } mysd(x) #&gt; My data #&gt; 1 2 3 4 5 #&gt; has std deviation 1.581139 pnorm(q=1.96, mean=1.96, sd=1) #&gt; [1] 0.5 The full syntax for pnorm() is pnorm(q, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE) pnorm(q=c(-1.96,1.96)) #&gt; [1] 0.0249979 0.9750021 x &lt;- c(3.68, -3.63, 0.80, 3.03, -9.86, -8.66, -2.38, 8.94, 0.52, 1.25) y &lt;- c(0.55, 1.65, 0.98, -0.07, -0.01, -0.31, -0.34, -1.38, -1.32, 0.53) x+y #&gt; [1] 4.23 -1.98 1.78 2.96 -9.87 -8.97 -2.72 7.56 -0.80 #&gt; [10] 1.78 x*y #&gt; [1] 2.0240 -5.9895 0.7840 -0.2121 0.0986 2.6846 #&gt; [7] 0.8092 -12.3372 -0.6864 0.6625 mean(x) #&gt; [1] -0.631 x-mean(x) #&gt; [1] 4.311 -2.999 1.431 3.661 -9.229 -8.029 -1.749 9.571 #&gt; [9] 1.151 1.881 x*2 #&gt; [1] 7.36 -7.26 1.60 6.06 -19.72 -17.32 -4.76 17.88 #&gt; [9] 1.04 2.50 The element(elt)-wise operation makes our life easier. 2.3 Files Click gpa.csv to download the GPA csv file. Click gpa.txt to download the GPA txt file. getwd() #&gt; [1] &quot;/Users/weishangjie/Documents/GitHub/Time-Series-Analysis&quot; gpatxt &lt;- read.table(&quot;gpa.txt&quot;, header=TRUE, sep=&quot;&quot;) gpacsv &lt;- read.csv(&quot;gpa.csv&quot;) gpacsv$HSGPA #&gt; [1] 3.04 2.35 2.70 2.55 2.83 4.32 3.39 2.32 2.69 2.83 2.39 #&gt; [12] 3.65 2.85 3.83 2.22 1.98 2.88 4.00 2.28 2.88 gpacsv$CollegeGPA #&gt; [1] 3.10 2.30 3.00 2.45 2.50 3.70 3.40 2.60 2.80 3.60 2.00 #&gt; [12] 2.90 3.30 3.20 2.80 2.40 2.60 3.80 2.20 2.60 gpacsv[1,1] # [row, col] #&gt; [1] 3.04 gpacsv[,1] #&gt; [1] 3.04 2.35 2.70 2.55 2.83 4.32 3.39 2.32 2.69 2.83 2.39 #&gt; [12] 3.65 2.85 3.83 2.22 1.98 2.88 4.00 2.28 2.88 gpacsv[c(1,3,5),2] #&gt; [1] 3.1 3.0 2.5 gpacsv[,&quot;HSGPA&quot;] #&gt; [1] 3.04 2.35 2.70 2.55 2.83 4.32 3.39 2.32 2.69 2.83 2.39 #&gt; [12] 3.65 2.85 3.83 2.22 1.98 2.88 4.00 2.28 2.88 summary(gpacsv) #&gt; HSGPA CollegeGPA #&gt; Min. :1.980 Min. :2.000 #&gt; 1st Qu.:2.380 1st Qu.:2.487 #&gt; Median :2.830 Median :2.800 #&gt; Mean :2.899 Mean :2.862 #&gt; 3rd Qu.:3.127 3rd Qu.:3.225 #&gt; Max. :4.320 Max. :3.800 plot(x = gpacsv$HSGPA, y = gpacsv$CollegeGPA, xlab = &quot;HS GPA&quot;, ylab = &quot;College GPA&quot;, main = &quot;College GPA vs. HS GPA&quot;, xlim = c(0,4.5), ylim = c(0,4.5), col = &quot;red&quot;, pch = 1, cex = 1.0, panel.first = grid(col = &quot;gray&quot;, lty = &quot;dotted&quot;)) The plot() function creates a two dimensional plot of data. Here are descriptions of its arguments: x specifies what is plotted for the x-axis. y specifies what is plotted for the y-axis. xlab and ylab specify the x-axis and y-axis labels, respectively. main specifies the main title of the plot. xlim and ylim specify the x-axis and y-axis limits, respectively. Notice the use of the c() function. col specifies the color of the plotting points. Run the colors() function to see what possible colors can be used. Also, you can see Here for the colors from colors(). pch specifies the plotting characters. cexspecifies the height of the plotting characters. The value 1.0 is the default. panel.first = grid() specifies grid lines will be plotted. The line types can be specified as follows: 1=solid, 2=dashed, 3=dotted, 4=dotdash, 5=longdash, 6=twodash or as one of the character strings \"blank\", \"solid\", \"dashed\", \"dotted\", \"dotdash\", \"longdash\", or \"twodash\". These line type specifications can be used in other functions. The par()(parameter) function’s Help contains more information about the different plotting options! 2.4 Regression Our model is:\\[CollegeGPA=\\beta_0+\\beta_1HSGPA+\\epsilon\\] mod.fit &lt;- lm(formula= CollegeGPA~ HSGPA, data=gpacsv) mod.fit #&gt; #&gt; Call: #&gt; lm(formula = CollegeGPA ~ HSGPA, data = gpacsv) #&gt; #&gt; Coefficients: #&gt; (Intercept) HSGPA #&gt; 1.0869 0.6125 names(mod.fit) #&gt; [1] &quot;coefficients&quot; &quot;residuals&quot; &quot;effects&quot; #&gt; [4] &quot;rank&quot; &quot;fitted.values&quot; &quot;assign&quot; #&gt; [7] &quot;qr&quot; &quot;df.residual&quot; &quot;xlevels&quot; #&gt; [10] &quot;call&quot; &quot;terms&quot; &quot;model&quot; mod.fit$coefficients #&gt; (Intercept) HSGPA #&gt; 1.0868795 0.6124941 round(mod.fit$residuals[1:5],2) #&gt; 1 2 3 4 5 #&gt; 0.15 -0.23 0.26 -0.20 -0.32 library(tidyverse) #&gt; ── Attaching packages ─────────────────── tidyverse 1.3.2 ── #&gt; ✔ ggplot2 3.4.1 ✔ purrr 1.0.1 #&gt; ✔ tibble 3.1.8 ✔ dplyr 1.1.0 #&gt; ✔ tidyr 1.3.0 ✔ stringr 1.5.0 #&gt; ✔ readr 2.1.4 ✔ forcats 0.5.2 #&gt; ── Conflicts ────────────────────── tidyverse_conflicts() ── #&gt; ✖ dplyr::filter() masks stats::filter() #&gt; ✖ dplyr::lag() masks stats::lag() save.fit &lt;- data.frame(gpacsv, C.GPA.hat = round(mod.fit$fitted.values,2), residuals = round(mod.fit$residuals,2)) save.fit %&gt;% head() #&gt; HSGPA CollegeGPA C.GPA.hat residuals #&gt; 1 3.04 3.10 2.95 0.15 #&gt; 2 2.35 2.30 2.53 -0.23 #&gt; 3 2.70 3.00 2.74 0.26 #&gt; 4 2.55 2.45 2.65 -0.20 #&gt; 5 2.83 2.50 2.82 -0.32 #&gt; 6 4.32 3.70 3.73 -0.03 summary(mod.fit) #&gt; #&gt; Call: #&gt; lm(formula = CollegeGPA ~ HSGPA, data = gpacsv) #&gt; #&gt; Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -0.55074 -0.25086 0.01633 0.24242 0.77976 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) 1.0869 0.3666 2.965 0.008299 ** #&gt; HSGPA 0.6125 0.1237 4.953 0.000103 *** #&gt; --- #&gt; Signif. codes: #&gt; 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Residual standard error: 0.3437 on 18 degrees of freedom #&gt; Multiple R-squared: 0.5768, Adjusted R-squared: 0.5533 #&gt; F-statistic: 24.54 on 1 and 18 DF, p-value: 0.0001027 Hence, our estimated regression model is\\[ \\hat{collge.GPA}=\\hat{\\beta_0}+\\hat{\\beta_1}HS.GPA =1.0869+0.6125HS.GPA\\] # Open a new graphics window # device new dev.new(width = 8, height = 6, pointsize = 10) # 1 row and 2 columns of plots par(mfrow = c(1,2)) # par= graphic parameter # mfrow= make a frame by row # Same scatter plot as before plot(x = gpacsv$HSGPA, y = gpacsv$CollegeGPA, xlab = &quot;HS GPA&quot;, ylab = &quot;College GPA&quot;, main = &quot;College GPA vs. HS GPA&quot;, xlim = c(0,4.5), ylim = c(0,4.5), col = &quot;red&quot;, pch = 1, cex = 1.0, panel.first = grid(col = &quot;gray&quot;, lty = &quot;dotted&quot;)) # Puts the line y = a + bx on the plot abline(a = mod.fit$coefficients[1], b = mod.fit$coefficients[2], lty = &quot;solid&quot;, col = &quot;blue&quot;, lwd = 2) # Same scatter plot as before plot(x = gpacsv$HSGPA, y = gpacsv$CollegeGPA, xlab = &quot;HS GPA&quot;, ylab = &quot;College GPA&quot;, main = &quot;College GPA vs. HS GPA&quot;, xlim = c(0,4.5), ylim = c(0,4.5), col = &quot;red&quot;, pch = 1, cex = 1.0, panel.first = grid(col = &quot;gray&quot;, lty = &quot;dotted&quot;)) # Add line # expr= math expression curve(expr = mod.fit$coefficients[1] + mod.fit$coefficients[2]*x, xlim = c(min(gpacsv$HSGPA),max(gpacsv$HSGPA)), col= &quot;blue&quot;, add = TRUE, lwd = 2) The dev.new() function can be used to open a new plotting window. The abline() function can be used to draw straight lines on a plot. In the format used here, the line y = a + bx was drawn where a was the (intercept) and b was the (slope). In the second plot, the curve() function was used to draw the line on the plot. This was done to have the line within the range of the high school GPA values. Let’s use function to automate what we have done. my.reg.func &lt;- function(x, y, data) { # Fit the simple linear regression model and save the results in mod.fit mod.fit &lt;- lm(formula = y ~ x, data = data) #Open a new graphics window - do not need to dev.new(width = 6, height = 6, pointsize = 10) # Same scatter plot as before plot(x = x, y = y, xlab = &quot;x&quot;, ylab = &quot;y&quot;, main = &quot;y vs. x&quot;, panel.first=grid(col = &quot;gray&quot;, lty = &quot;dotted&quot;)) # Plot model curve(expr = mod.fit$coefficients[1] + mod.fit$coefficients[2]*x, xlim = c(min(x),max(x)), col = &quot;blue&quot;, add = TRUE) # This is the object returned mod.fit } save.it &lt;- my.reg.func(x = gpacsv$HSGPA, y = gpacsv$CollegeGPA, data = gpacsv) To get specific x-axis or y-axis tick marks on a plot, use the axis() function. For example, #Note that xaxt = &quot;n&quot; tells R to not give any labels on the # x-axis (yaxt = &quot;n&quot; works for y-axis) plot(x = gpacsv$HSGPA, y = gpacsv$CollegeGPA, xlab = &quot;HS GPA&quot;, ylab = &quot;College GPA&quot;, main = &quot;College GPA vs. HS GPA&quot;, xaxt = &quot;n&quot;, xlim = c(0, 4.5), ylim = c(0, 4.5), col = &quot;red&quot;, pch = 1) plot(x = gpacsv$HSGPA, y = gpacsv$CollegeGPA, xlab = &quot;HS GPA&quot;, ylab = &quot;College GPA&quot;, main = &quot;College GPA vs. HS GPA&quot;, xaxt = &quot;n&quot;, xlim = c(0, 4.5), ylim = c(0, 4.5), col = &quot;red&quot;, pch = 1) #Major tick marks axis(side = 1, at = seq(from = 0, to = 4.5, by = 0.5)) plot(x = gpacsv$HSGPA, y = gpacsv$CollegeGPA, xlab = &quot;HS GPA&quot;, ylab = &quot;College GPA&quot;, main = &quot;College GPA vs. HS GPA&quot;, xaxt = &quot;n&quot;, xlim = c(0, 4.5), ylim = c(0, 4.5), col = &quot;red&quot;, pch = 1) #Major tick marks axis(side = 1, at = seq(from = 0, to = 4.5, by = 0.5)) #Minor tick marks axis(side = 1, at = seq(from = 0, to = 4.5, by = 0.1), tck = 0.01, labels = FALSE) 2.5 Object-Oriented Language Functions are typically designed to operate on only one or very few classes of objects. However, some functions, like summary(), are generic, in the sense that essentially different versions of them have been constructed to work with different classes of objects. When a generic function is run with an object, R first checks the object’s class type and then looks to find a method function with the name format &lt;generic function&gt;.&lt;class name&gt;. Below are examples for summary(): summary(mod.fit) – The function summary.lm() summarizes the regression model summary(gpacsv) – The function summary.data.frame() summarizes the data frame’s contents summary.default() – R attempts to run this function if there is no method function for a class There are many generic functions! For example, plot() is a generic function (tryplot(mod.fit) to see what happens!). We will also see other generic functions like predict() later in the notes. plot(mod.fit) The purpose of generic functions is to use a familiar language set with any object. So it is convenient to use the same language set no matter the application. This is why R is referred to as an object-oriented language. To see a list of all method functions associated with a class, use methods(class = &lt;class name&gt;). For the regression example, the method functions associated with the lm class are: methods(class=&quot;lm&quot;) %&gt;% head() #&gt; [1] &quot;add1.lm&quot; &quot;alias.lm&quot; #&gt; [3] &quot;anova.lm&quot; &quot;case.names.lm&quot; #&gt; [5] &quot;coerce,oldClass,S3-method&quot; &quot;confint.lm&quot; To see a list of all method functions for a generic function, use methods(generic.function = &lt;generic function name&gt;) methods(generic.function = &quot;summary&quot;) %&gt;% head() #&gt; [1] &quot;summary,ANY-method&quot; #&gt; [2] &quot;summary,DBIObject-method&quot; #&gt; [3] &quot;summary.aov&quot; #&gt; [4] &quot;summary.aovlist&quot; #&gt; [5] &quot;summary.aspell&quot; #&gt; [6] &quot;summary.check_packages_in_dir&quot; Knowing what a name of a particular method function can be helpful to find help on it. For example, the help for summary() alone is not very helpful! However, the help for summary.lm()provides a lot of useful information about what is summarized for a regression model. "],["time-series-basics-plotting.html", "Chapter 3 Time Series Basics-Plotting 3.1 Example Data 3.2 S&amp;P500 Index 3.3 Sunspots", " Chapter 3 Time Series Basics-Plotting In this chapter, we will go over some Time Series examples. The aim of this chapter is to help you grasp some of the ideas about plotting. 3.1 Example Data Click OSU_enroll.csv to download data. osu.enroll &lt;- read.csv(file = &quot;OSU_enroll.csv&quot;, stringsAsFactors = TRUE) head(osu.enroll) #&gt; t Semester Year Enrollment date #&gt; 1 1 Fall 1989 20110 8/31/1989 #&gt; 2 2 Spring 1990 19128 2/1/1990 #&gt; 3 3 Summer 1990 7553 6/1/1990 #&gt; 4 4 Fall 1990 19591 8/31/1990 #&gt; 5 5 Spring 1991 18361 2/1/1991 #&gt; 6 6 Summer 1991 6702 6/1/1991 tail(osu.enroll) #&gt; t Semester Year Enrollment date #&gt; 35 35 Spring 2001 20004 2/1/2001 #&gt; 36 36 Summer 2001 7558 6/1/2001 #&gt; 37 37 Fall 2001 21872 8/31/2001 #&gt; 38 38 Spring 2002 20922 2/1/2002 #&gt; 39 39 Summer 2002 7868 6/1/2002 #&gt; 40 40 Fall 2002 22992 8/31/2002 x &lt;- osu.enroll$Enrollment #One way to do plot dev.new(width = 8, height = 6, pointsize = 10) # we did not specify y-axis and R put our x in y-axis, time in x-axis plot(x = x, ylab = &quot;OSU Enrollment&quot;, xlab = &quot;t (time)&quot;, type=&quot;l&quot;, col = &quot;red&quot;, main = &quot;OSU Enrollment from Fall 1989 to Fall 2002&quot;, panel.first = grid(col = &quot;gray&quot;, lty = &quot;dotted&quot;)) dev.new(width = 8, height = 6, pointsize = 10) # we did not specify y-axis and R put our x in y-axis, time in x-axis plot(x = x, ylab = &quot;OSU Enrollment&quot;, xlab = &quot;t (time)&quot;, type=&quot;l&quot;, col = &quot;red&quot;, main = &quot;OSU Enrollment from Fall 1989 to Fall 2002&quot;, panel.first = grid(col = &quot;gray&quot;, lty = &quot;dotted&quot;)) points(x = osu.enroll$Enrollment, pch = 20, col = &quot;blue&quot;) Altenatively, you can do the same thing using ggplot. library(ggplot2) # Create a data frame df &lt;- data.frame(osu.enroll) # Create the plot ggplot(df, aes(x = t, y = Enrollment)) + geom_line(colour = &quot;red&quot;) + # Line plot geom_point(shape = 20, colour = &quot;blue&quot;) + # Add points labs(x = &quot;t (time)&quot;, y = &quot;OSU Enrollment&quot;, title = &quot;OSU Enrollment from Fall 1989 to Fall 2002&quot;) + # Set axis labels and title theme_bw() + # Set the theme to a white background with black lines theme(panel.grid.major = element_line(colour = &quot;gray&quot;, linetype = &quot;dotted&quot;)) # Add gray dotted lines to the plot When only x is specified in the plot() function, R puts this on the y-axis and uses the observation number on the x-axis. Compare this to the next plot below where both x and y arguments are specified. #More complicated plot fall &lt;- osu.enroll[osu.enroll$Semester == &quot;Fall&quot;,] spring &lt;- osu.enroll[osu.enroll$Semester == &quot;Spring&quot;,] summer &lt;- osu.enroll[osu.enroll$Semester == &quot;Summer&quot;,] plot(y = fall$Enrollment, x = fall$t, ylab = &quot;OSU Enrollment&quot;, xlab = &quot;t (time)&quot;, col = &quot;blue&quot;, main = &quot;OSU Enrollment from Fall 1989 to Fall 2002&quot;, panel.first = grid(col = &quot;gray&quot;, lty = &quot;dotted&quot;), pch = 1, type = &quot;o&quot;, ylim = c(0,max(osu.enroll$Enrollment))) lines(y = spring$Enrollment, x = spring$t, col = &quot;red&quot;, type = &quot;o&quot;, pch = 2) lines(y = summer$Enrollment, x = summer$t, col = &quot;darkgreen&quot;, type = &quot;o&quot;, pch = 3) legend(x=&quot;center&quot;, legend= c(&quot;Fall&quot;,&quot;Spring&quot;,&quot;Summer&quot;), pch=c(1,2,3), lty=c(1,1,1), col=c(&quot;blue&quot;,&quot;red&quot;,&quot;darkgreen&quot;), bty=&quot;n&quot;) #Another way to do plot with actual dates plot(y = osu.enroll$Enrollment, x = as.Date(osu.enroll$date, format = &quot;%m/%d/%Y&quot;), xlab = &quot;Time&quot;, type = &quot;l&quot;, col = &quot;red&quot;, main = &quot;OSU Enrollment from Fall 1989 to Fall 2002&quot;, ylab = &quot;OSU Enrollment&quot;) points(y = osu.enroll$Enrollment, x = as.Date(osu.enroll$date, format = &quot;%m/%d/%Y&quot;), pch = 20, col = &quot;blue&quot;) #Create own gridlines # v specifies vertical line; h specifies horizontal line abline(v = as.Date(c(&quot;1990/1/1&quot;, &quot;1992/1/1&quot;, &quot;1994/1/1&quot;, &quot;1996/1/1&quot;, &quot;1998/1/1&quot;, &quot;2000/1/1&quot;, &quot;2002/1/1&quot;)), lty = &quot;dotted&quot;, col = &quot;lightgray&quot;) abline(h = c(10000, 15000, 20000), lty = &quot;dotted&quot;, col = &quot;lightgray&quot;) 3.2 S&amp;P500 Index Click SP500weekly.csv to download data. SP500 &lt;- read.csv(file=&quot;SP500weekly.csv&quot;,stringsAsFactors = TRUE) head(SP500) #&gt; WeekStart Open High Low Close AdjClose Volume #&gt; 1 1/1/1995 459.21 462.49 457.20 460.68 460.68 1199080000 #&gt; 2 1/8/1995 460.67 466.43 458.65 465.97 465.97 1627330000 #&gt; 3 1/15/1995 465.97 470.43 463.99 464.78 464.78 1667400000 #&gt; 4 1/22/1995 464.78 471.36 461.14 470.39 470.39 1628110000 #&gt; 5 1/29/1995 470.39 479.91 467.49 478.65 478.65 1888560000 #&gt; 6 2/5/1995 478.64 482.60 478.36 481.46 481.46 1579920000 tail(SP500) #&gt; WeekStart Open High Low Close AdjClose #&gt; 1395 9/19/2021 4402.95 4465.40 4305.91 4455.48 4455.48 #&gt; 1396 9/26/2021 4442.12 4457.30 4288.52 4357.04 4357.04 #&gt; 1397 10/3/2021 4348.84 4429.97 4278.94 4391.34 4391.34 #&gt; 1398 10/10/2021 4385.44 4475.82 4329.92 4471.37 4471.37 #&gt; 1399 10/17/2021 4463.72 4559.67 4447.47 4544.90 4544.90 #&gt; 1400 10/24/2021 4553.69 4608.08 4537.36 4605.38 4605.38 #&gt; Volume #&gt; 1395 15697030000 #&gt; 1396 15555390000 #&gt; 1397 14795520000 #&gt; 1398 13758090000 #&gt; 1399 13966070000 #&gt; 1400 16206040000 x &lt;- SP500$Close #One way to do plot dev.new(width = 8, height = 6, pointsize = 10) #again, we do not specify y-axis here plot(x = x, ylab = &quot;S&amp;P 500 Index&quot;, xlab = &quot;t (time)&quot;, type = &quot;l&quot;, col = &quot;red&quot;, main = &quot;S&amp;P 500 Index from 1/1/1995 to 10/25/2021 (weekly)&quot;, panel.first = grid(col = &quot;gray&quot;, lty = &quot;dotted&quot;)) #Another way to do plot with actual dates plot(y = x, x = as.Date(SP500$WeekStart, format = &quot;%m/%d/%Y&quot;), xlab = &quot;Time&quot;, type = &quot;l&quot;, col = &quot;red&quot;, main = &quot;S&amp;P 500 Index from 1/1/1995 to 10/25/2021 (weekly)&quot;, ylab = &quot;S&amp;P 500 Index&quot;) #Create own gridlines abline(v = as.Date(c(&quot;1995/1/1&quot;, &quot;2000/1/1&quot;, &quot;2005/1/1&quot;, &quot;2010/1/1&quot;, &quot;2015/1/1&quot;, &quot;2020/1/1&quot;)), lty = &quot;dotted&quot;, col = &quot;lightgray&quot;) abline(h = seq(from = 0, to = 5000, by = 1000), lty = &quot;dotted&quot;, col = &quot;lightgray&quot;) # One more way with fine control of the dates plot(y = x, x = as.Date(SP500$WeekStart, format = &quot;%m/%d/%Y&quot;), xlab = &quot;Time&quot;, type = &quot;l&quot;, col = &quot;red&quot;, main = &quot;S&amp;P 500 Index from 1/1/1995 to 10/25/2021 (weekly)&quot;, ylab = &quot;S&amp;P 500 Index&quot;, xaxt = &quot;n&quot;) axis.Date(side = 1, at = seq(from = as.Date(&quot;1995/1/1&quot;), to = as.Date(&quot;2021/12/31&quot;), by = &quot;years&quot;), labels = format(x = seq(from = as.Date(&quot;1995/1/1&quot;), to = as.Date(&quot;2021/12/31&quot;), by = &quot;years&quot;), format = &quot;%b%y&quot;), las = 2) #las changes orientation of labels #Create own gridlines abline(v = as.Date(c(&quot;1995/1/1&quot;, &quot;2000/1/1&quot;, &quot;2005/1/1&quot;, &quot;2010/1/1&quot;, &quot;2015/1/1&quot;, &quot;2020/1/1&quot;)), lty = &quot;dotted&quot;, col = &quot;lightgray&quot;) abline(h = seq(from = 0, to = 5000, by = 1000), lty = &quot;dotted&quot;, col = &quot;lightgray&quot;) 3.3 Sunspots Click SN_y_tot_V2.0.csv to download data. sunspots &lt;- read.table(file = &quot;SN_y_tot_V2.0.csv&quot;, sep = &quot;;&quot;, col.names = c(&quot;Mid.year&quot;, &quot;Mean.total&quot;, &quot;Mean.SD.total&quot;, &quot;Numb.obs.used&quot;, &quot;Definitive&quot;)) head(sunspots) #&gt; Mid.year Mean.total Mean.SD.total Numb.obs.used #&gt; 1 1700.5 8.3 -1 -1 #&gt; 2 1701.5 18.3 -1 -1 #&gt; 3 1702.5 26.7 -1 -1 #&gt; 4 1703.5 38.3 -1 -1 #&gt; 5 1704.5 60.0 -1 -1 #&gt; 6 1705.5 96.7 -1 -1 #&gt; Definitive #&gt; 1 1 #&gt; 2 1 #&gt; 3 1 #&gt; 4 1 #&gt; 5 1 #&gt; 6 1 tail(sunspots) #&gt; Mid.year Mean.total Mean.SD.total Numb.obs.used #&gt; 316 2015.5 69.8 6.4 8903 #&gt; 317 2016.5 39.8 3.9 9940 #&gt; 318 2017.5 21.7 2.5 11444 #&gt; 319 2018.5 7.0 1.1 12611 #&gt; 320 2019.5 3.6 0.5 12884 #&gt; 321 2020.5 8.8 4.1 14440 #&gt; Definitive #&gt; 316 1 #&gt; 317 1 #&gt; 318 1 #&gt; 319 1 #&gt; 320 1 #&gt; 321 1 dev.new(width = 8, height = 6, pointsize = 10) #again, we did not specify y-axis here plot(x = sunspots$Mean.total, ylab = &quot;Number of sunspots&quot;, xlab = &quot;t (time)&quot;, type = &quot;l&quot;, col = &quot;red&quot;, main = &quot;Sunspots per year from 1700 to 2020&quot;, panel.first = grid(col = &quot;gray&quot;, lty = &quot;dotted&quot;)) points(x = sunspots$Mean.total, pch = 20, col = &quot;blue&quot;) # Include dates plot(y = sunspots$Mean.total, x = sunspots$Mid.year, ylab = &quot;Number of sunspots&quot;, xlab = &quot;Year&quot;, type = &quot;l&quot;, col = &quot;red&quot;, main = &quot;Sunspots per year from 1700 to 2020&quot;, panel.first = grid(col = &quot;gray&quot;, lty = &quot;dotted&quot;)) points(y = sunspots$Mean.total, x = sunspots$Mid.year, pch = 20, col = &quot;blue&quot;) #Convert to an object of class &quot;ts&quot; x &lt;- ts(data = sunspots$Mean.total, start = 1700, frequency = 1) x #&gt; Time Series: #&gt; Start = 1700 #&gt; End = 2020 #&gt; Frequency = 1 #&gt; [1] 8.3 18.3 26.7 38.3 60.0 96.7 48.3 33.3 16.7 #&gt; [10] 13.3 5.0 0.0 0.0 3.3 18.3 45.0 78.3 105.0 #&gt; [19] 100.0 65.0 46.7 43.3 36.7 18.3 35.0 66.7 130.0 #&gt; [28] 203.3 171.7 121.7 78.3 58.3 18.3 8.3 26.7 56.7 #&gt; [37] 116.7 135.0 185.0 168.3 121.7 66.7 33.3 26.7 8.3 #&gt; [46] 18.3 36.7 66.7 100.0 134.8 139.0 79.5 79.7 51.2 #&gt; [55] 20.3 16.0 17.0 54.0 79.3 90.0 104.8 143.2 102.0 #&gt; [64] 75.2 60.7 34.8 19.0 63.0 116.3 176.8 168.0 136.0 #&gt; [73] 110.8 58.0 51.0 11.7 33.0 154.2 257.3 209.8 141.3 #&gt; [82] 113.5 64.2 38.0 17.0 40.2 138.2 220.0 218.2 196.8 #&gt; [91] 149.8 111.0 100.0 78.2 68.3 35.5 26.7 10.7 6.8 #&gt; [100] 11.3 24.2 56.7 75.0 71.8 79.2 70.3 46.8 16.8 #&gt; [109] 13.5 4.2 0.0 2.3 8.3 20.3 23.2 59.0 76.3 #&gt; [118] 68.3 52.9 38.5 24.2 9.2 6.3 2.2 11.4 28.2 #&gt; [127] 59.9 83.0 108.5 115.2 117.4 80.8 44.3 13.4 19.5 #&gt; [136] 85.8 192.7 227.3 168.7 143.0 105.5 63.3 40.3 18.1 #&gt; [145] 25.1 65.8 102.7 166.3 208.3 182.5 126.3 122.0 102.7 #&gt; [154] 74.1 39.0 12.7 8.2 43.4 104.4 178.3 182.2 146.6 #&gt; [163] 112.1 83.5 89.2 57.8 30.7 13.9 62.8 123.6 232.0 #&gt; [172] 185.3 169.2 110.1 74.5 28.3 18.9 20.7 5.7 10.0 #&gt; [181] 53.7 90.5 99.0 106.1 105.8 86.3 42.4 21.8 11.2 #&gt; [190] 10.4 11.8 59.5 121.7 142.0 130.0 106.6 69.4 43.8 #&gt; [199] 44.4 20.2 15.7 4.6 8.5 40.8 70.1 105.5 90.1 #&gt; [208] 102.8 80.9 73.2 30.9 9.5 6.0 2.4 16.1 79.0 #&gt; [217] 95.0 173.6 134.6 105.7 62.7 43.5 23.7 9.7 27.9 #&gt; [226] 74.0 106.5 114.7 129.7 108.2 59.4 35.1 18.6 9.2 #&gt; [235] 14.6 60.2 132.8 190.6 182.6 148.0 113.0 79.2 50.8 #&gt; [244] 27.1 16.1 55.3 154.3 214.7 193.0 190.7 118.9 98.3 #&gt; [253] 45.0 20.1 6.6 54.2 200.7 269.3 261.7 225.1 159.0 #&gt; [262] 76.4 53.4 39.9 15.0 22.0 66.8 132.9 150.0 149.4 #&gt; [271] 148.0 94.4 97.6 54.1 49.2 22.5 18.4 39.3 131.0 #&gt; [280] 220.1 218.9 198.9 162.4 91.0 60.5 20.6 14.8 33.9 #&gt; [289] 123.0 211.1 191.8 203.3 133.0 76.1 44.9 25.1 11.6 #&gt; [298] 28.9 88.3 136.3 173.9 170.4 163.6 99.3 65.3 45.8 #&gt; [307] 24.7 12.6 4.2 4.8 24.9 80.8 84.5 94.0 113.3 #&gt; [316] 69.8 39.8 21.7 7.0 3.6 8.8 class(x) #&gt; [1] &quot;ts&quot; class(sunspots$Mean.total) #&gt; [1] &quot;numeric&quot; 3.3.1 plot.ts() plot() is a generic function - uses the plot.ts() method function # we did not specify y-axis here, but x is now ts plot(x = x, ylab = expression(paste(x[t], &quot; (Number of sunspots)&quot;)), xlab = &quot;Year&quot;, type = &quot;o&quot;, col = &quot;red&quot;, main = &quot;Sunspots per year from 1700 to 2020&quot;) "],["time-series-basics-basic-model.html", "Chapter 4 Time Series Basics-Basic Model 4.1 White Noise 4.2 Moving Average 4.3 Autoregression", " Chapter 4 Time Series Basics-Basic Model In this chapter, we will go introduce some basic Time Series model. Hopefully, we can discuss them in details in the following chapters. Definition 4.1 Stochastic process Stochastic process is a collection of random variables \\(\\{X_t\\}\\) indexed by t. Time Series is a collection of random vatiables indexed according to the order they are obtained in time. A realization of the stochastic process is the observed values. 4.1 White Noise Example 4.1 White Noise \\(W_t\\sim \\mathrm{i.i.d.} (0,\\sigma^2) , \\forall t=1,...,n\\) usually, we assume normal distribution, i.e., \\(W_t\\sim \\mathrm{i.i.d.} N(0,\\sigma^2) , \\forall t=1,...,n\\) set.seed(8128) w &lt;- rnorm(n = 100, mean = 0, sd = 1) head(w) #&gt; [1] -0.10528941 0.25548490 0.82065388 0.04070997 #&gt; [5] -0.66722880 -1.54502793 dev.new(width = 6, height = 6, pointsize = 10) # we did not specify y-axis here # note that we use expression() to type math expression plot(x = w, ylab = expression(w[t]), xlab = &quot;t&quot;, type = &quot;o&quot;, col = &quot;red&quot;, main = expression(paste(&quot;White noise where &quot;, w[t], &quot; ~ ind. N(0, 1)&quot;)), panel.first = grid(col = &quot;gray&quot;, lty = &quot;dotted&quot;)) #&gt; Warning in title(...): font metrics unknown for character #&gt; 0xa #&gt; Warning in title(...): font metrics unknown for character #&gt; 0xa #Advantage of second plot is separate control over color of points plot(x = w, ylab = expression(w[t]), xlab = &quot;t&quot;, type = &quot;l&quot;, col = &quot;red&quot;, main = expression(paste(&quot;White noise where &quot;, w[t], &quot; ~ ind. N(0, 1)&quot;)), panel.first = grid(col = &quot;gray&quot;, lty = &quot;dotted&quot;)) points(x = w, pch = 20, col = &quot;blue&quot;) Suppose another white noise process is simulated. Below is a plot overlaying the two time series. set.seed(1298) w.new &lt;- rnorm(n = 100, mean = 0, sd = 1) head(w.new) #&gt; [1] 1.08820292 -1.46217413 -1.10887422 0.55156914 #&gt; [5] 0.70582813 0.05079594 plot(x = w, ylab = expression(w[t]), xlab = &quot;t&quot;, type = &quot;l&quot;, col = &quot;red&quot;, main = expression(paste(&quot;White noise where &quot;, w[t], &quot; ~ ind. N(0, 1)&quot;)), panel.first = grid(col = &quot;gray&quot;, lty = &quot;dotted&quot;)) points(x = w, pch = 20, col = &quot;blue&quot;) lines(x = w.new, col = &quot;green&quot;) points(x = w.new, pch = 20,col = &quot;orange&quot;) legend(x =&quot;top&quot;,legend=c(&quot;Time series 1&quot;, &quot;Time series 2&quot;), lty=c(1,1), col=c(&quot;red&quot;, &quot;green&quot;), bty=&quot;n&quot;) We could also plot the two time series separately. #make frame by row 2 rows 1 cols par(mfrow = c(2,1)) plot(x = w, ylab = expression(w[t]), xlab = &quot;t&quot;, type = &quot;l&quot;, col = &quot;red&quot;, main = expression(paste(&quot;White noise where &quot;, w[t], &quot;~N(0, 1)&quot;)), panel.first = grid(col = &quot;gray&quot;, lty = &quot;dotted&quot;)) points(x = w, pch = 20, col = &quot;blue&quot;) plot(x = w.new, ylab = expression(w.new[t]), xlab = &quot;t&quot;, type = &quot;l&quot;, col = &quot;green&quot;, main = expression(paste(&quot;White noise where &quot;, w[t], &quot; ~ ind.N(0, 1)&quot;)), panel.first=grid(col = &quot;gray&quot;, lty = &quot;dotted&quot;)) points(x = w.new, pch = 20, col = &quot;orange&quot;) 4.2 Moving Average Example 4.2 Moving Average of White Noise The previous time series had no correlation between the observations. One way to induce correlation is to create a “moving average” of the observations. This will have an effect of “smoothing” the series. Let \\(m_t = \\frac{w_t+w_{t-1}+w_{t-2}}{3}\\). This can be done in R using the following code: set.seed(8128) w &lt;- rnorm(n=100,mean=0, sd=1) head(w) #&gt; [1] -0.10528941 0.25548490 0.82065388 0.04070997 #&gt; [5] -0.66722880 -1.54502793 # rep(1/3,3) repeats 1/3 3 times m &lt;- filter(x=w, filter = rep(1/3, 3), method=&quot;convolution&quot;, sides=1) head(m) #&gt; [1] NA NA 0.32361646 0.37228292 #&gt; [5] 0.06471168 -0.72384892 tail(m) #&gt; [1] 0.3158762 -0.1803096 0.2598066 -0.6450531 -0.5879723 #&gt; [6] -0.9120182 (w[1]+w[2]+w[3])/3 #&gt; [1] 0.3236165 (w[98]+w[99]+w[100])/3 #&gt; [1] -0.9120182 plot(x = w, ylab = expression(paste(m[t], &quot; or &quot;, w[t])), xlab = &quot;t&quot;, type = &quot;l&quot;, col = &quot;red&quot;, panel.first = grid(col = &quot;gray&quot;, lty = &quot;dotted&quot;), lty = &quot;dotted&quot;) points(x = w, pch = 20, col = &quot;blue&quot;) lines(x = m, col = &quot;brown&quot;, lty = &quot;solid&quot;, lwd = 4) points(x = m, pch = 20, col = &quot;orange&quot;) legend(x = &quot;top&quot;, legend = c(&quot;MA, 3 points&quot;, &quot;White noise&quot;), lty = c(&quot;solid&quot;, &quot;dotted&quot;), col=c(&quot;brown&quot;, &quot;red&quot;), lwd = c(4,1), bty = &quot;n&quot;) The plot below shows a 7-point moving average. m7 &lt;- filter(x=w, filter=rep(x=1/7, times=7),method=&quot;convolution&quot;, sides=1) plot(x=w, ylab=expression(paste(m[t],&quot;or&quot;,w[t])), xlab=&quot;t&quot;,type=&quot;l&quot;,col=&quot;red&quot;,panel_filter=grid(col=&quot;gray&quot;,lty=&quot;dotted&quot;), lty=&quot;dotted&quot;) points(x=w, pch=20, col=&quot;blue&quot;) lines(x=m, col=&quot;brown&quot;, lty=&quot;solid&quot;,lwd=4) points(x=m, pch=20, col=&quot;orange&quot;) lines(x = m7, col = &quot;lightgreen&quot;, lty = &quot;solid&quot;, lwd = 4) points(x = m7, pch = 20, col = &quot;darkgreen&quot;) legend(x = &quot;top&quot;, legend = c(&quot;MA, 3 points&quot;, &quot;White noise&quot;, &quot;MA 7 points&quot;), lty = c(&quot;solid&quot;, &quot;dotted&quot;, &quot;solid&quot;), col = c(&quot;brown&quot;, &quot;red&quot;, &quot;lightgreen&quot;), lwd = c(2,1,4), bty=&quot;n&quot;) 4.3 Autoregression Example 4.3 Autoregression An autoregression model uses past observations to predict future observations in a regression model. Suppose the autoregression model is \\(x_t = 0.7x_{t-1} + w_t, w_t \\sim \\mathrm{i.i.d.} N(0,1) ,\\forall t = 1, …, n\\) Because there is one past period on the right hand side, this is often denoted as an AR(1) model Obviously, there will be a correlation between the random variables. set.seed(6381) #Different seed from white_noise.R w &lt;- rnorm(n = 200, mean = 0, sd = 1) head(w) #&gt; [1] 0.06737166 -0.68095839 0.78930605 0.60049855 #&gt; [5] -1.21297680 -1.14082872 #Simple way to simulate AR(1) data x &lt;- numeric(length = 200) x.1 &lt;- 0 for(i in 1:length(x)) { x[i] &lt;- 0.7*x.1 + w[i] x.1 &lt;- x[i] } head(data.frame(x, w)) #&gt; x w #&gt; 1 0.06737166 0.06737166 #&gt; 2 -0.63379823 -0.68095839 #&gt; 3 0.34564730 0.78930605 #&gt; 4 0.84245166 0.60049855 #&gt; 5 -0.62326064 -1.21297680 #&gt; 6 -1.57711117 -1.14082872 #Do not use first 100 x &lt;- x[101:200] plot(x = x, ylab = expression(x[t]), xlab = &quot;t&quot;, type = &quot;l&quot;, col = c(&quot;red&quot;), lwd = 1 , main = expression(paste(&quot;AR(1): &quot;, x[t] == 0.7*x[t-1] + w[t])), panel.first = grid(col = &quot;gray&quot;, lty = &quot;dotted&quot;)) points(x = x, pch = 20, col = &quot;blue&quot;) Here is an easier way to simulate observations from an AR(1). Note that this uses an Autoregressive Integrated Moving Average (ARIMA) structure that we will discuss later in the course. In this case, I use \\(\\sigma_w\\)= 10. set.seed(7181) x &lt;- arima.sim(model = list(ar = c(0.7)), n = 100, rand.gen = rnorm, sd = 10) plot(x = x, ylab = expression(x[t]), xlab = &quot;t&quot;, type = &quot;l&quot;, col = &quot;red&quot;, lwd = 1 ,main = expression(paste(&quot;AR(1): &quot;, x[t] == 0.7*x[t-1] + w[t])), panel.first=grid(col = &quot;gray&quot;, lty = &quot;dotted&quot;)) points(x = x, pch = 20, col = &quot;blue&quot;) "],["time-series-basics-dependence.html", "Chapter 5 Time Series Basics-Dependence", " Chapter 5 Time Series Basics-Dependence We would like to understand the relationship among all random variables in a time series. In order to do that, we would need to look at the joint distribution function. Suppose the time series consists of the random variables . The cumulative joint distribution function for these random variables is: \\[ F(c_1, c_2, …, c_n) = P(X_1\\leq{c_1},X_2\\leq{c_2},...,X_n\\leq{c_n}) \\] This can be VERY difficult to examine over the MULTIDIMENSIONS. The one-dimensional cumulative distributional function is denoted by $ F_t(x) = P(X_t) $for a random variable \\(X_t\\) at time t. The corresponding probability distribution function is \\(f_t(x)=\\frac{\\partial{F_t(x)}}{\\partial{x}}\\) The mean value function is \\(\\mu_t=E(X_t)=\\int{xf_t(x)dx}\\) Important: The interpretation of \\(\\mu_t\\) is that it represents the mean taken over ALL possible events that could have produced \\(x_t\\). Another way to think about it is suppose that \\(x_1,\\dots,x_n\\) is observed an infinite number of times. Then \\(\\mu_1\\) represents the average value at time 1, \\(\\mu_2\\) represents the average value at time 2, … Example 5.1 Moving Average Let \\(m_t=\\frac{(w_t+w_{t-1}+w_{t-2})}{3}\\), where \\(w_t\\sim\\mathrm{i.i.d.}N(0,1)\\forall t=1,...,n\\) Then \\(\\mu_t=E(m_t)=E[\\frac{(w_t+w_{t-1}+w_{t-2})}{3}]=\\frac{1}{3}[E(w_t)+E(w_{t-1})+E(w_{t-2})]=0\\) Example 5.2 Autoregressions Let \\(x_t = 0.7x_{t-1} + w_t, w_t \\sim \\mathrm{i.i.d.} N(0,1) ,\\forall t = 1, …, n\\) Then \\(\\mu_t=E(x_t)=E[0.7x_{t-1} + w_t]=0.7E(x_{t-1})+E(w_t)=0.7E(0.7x_{t-2}+w_{t-1})+0=...=0\\) Autocovariance function To assess the dependence between two random variables, we need to examine the two-dimensional cumulative distribution function. This can be denoted as $F(c_s, c_t) = P(X_s c_s, X_t c_t) $for two different time points s and t. In another course, you learned about the covariance function which measures the linear dependence between two random variables:For two random variables X and Y, the covariance between them is $$Cov(X,Y) = E[(X – _x)(Y – _y)] = E(XY) – _x_y, _x = E(X) , _y = E(Y)$$ Because we are interested in linear dependence between two random variables in the same time series, we will examine the autocovariance function: \\[\\gamma (s,t) = Cov(X_s, X_t) = E[(X_s – \\mu_s)(X_t – \\mu_t)]= \\int\\int(x_s-\\mu_s)(x_t-\\mu_t)f(x_s,x_t)dx_sdx_t ,\\forall s, t \\] where\\(f(X_s,X_t)=\\frac{\\partial{F(X_s,X_t)}}{\\partial{X_s}\\partial{X_t}}\\)and assuming continuous random variables If the autocovariance is 0, there is no linear dependence. If s = t, the autocovariance is the variance: \\(\\gamma (t,t) = E[(X_t-\\mu_t)^2]\\) Example 5.3 White Noise Suppose \\(w_t \\sim ind. N(0,\\sigma^2_w ), t=1,…,n.\\) if $ s=t, (s,t)=$ if $ st, (s,t)=$ \\[\\begin{cases} \\gamma(s,t)= &amp; \\text{if } s=t \\\\ \\gamma(s,t)= &amp; \\text{if } s\\ne t \\end{cases}\\] Example 5.4 Moving Average Let \\(m_t=\\frac{w_t+w_{t-1}+w_{t-2}}{3}, w_t \\sim ind. N(0,1 ), t=1,…,n\\) \\(\\gamma (s,t)=E[(m_s-\\mu_s)(m_t-\\mu_t)]=E[m_sm_t]\\) b/c \\(\\mu_s=\\mu_t=0\\) Then \\(E[m_sm_t]=E[\\frac{w_s+w_{s-1}+w_{s-2}}{3}\\frac{w_t+w_{t-1}+w_{t-2}}{3}]=\\frac{1}{9}E[(w_s+w_{s-1}+w_{s-2})(w_t+w_{t-1}+w_{t-2})]\\) To find this, we need to examine a few different cases: s = t \\[E[m_tm_t] = E[m^2_t] = Var(m_t) + [E(m_t)]^2 = \\frac{1}{9}Var(w_t + w_{t-1} + w_{t-2}) + 0\\\\= \\frac{1}{9}{Var(w_t) + Var(w_{t-1}) + Var(w_{t-2})} = \\frac{1}{9}(1+1+1) = 3/9\\] s = t - 1 $$E[m_{t-1}m_t] =E[(w_{t-1} + w_{t-2} + w_{t-3})(w_t + w_{t-1} + w_{t-2})]\\ = [E(w_{t-1})E(w_t) + E(w^2_{t-1}) + E(w_{t-1})E(w_{t-2}) \\ + E(w_{t-2})E(w_t) + E(w_{t-2})E(w_{t-1}) + E(w^2_{t-2}) \\ + E(w_{t-3})E(w_t) + E(w_{t-3})E(w_{t-1}) + E(w_{t-3})E(w_{t-2})]\\ =[0 + 1 + 0 + 0 + 0 + 1 + 0 + 0 + 0]=2/9$$ \\(E(w^2_{t-1}) = 1\\), because \\(Var(w_{t-1}) = 1\\) s = t - 2 $$E[m_{t-2}m_t] = E[(w_{t-2} + w_{t-3} + w_{t-4})(w_t + w_{t-1} + w_{t-2})]\\ = [E(w_{t-2}w_t) + E(w_{t-2}w_{t-1}) + E(w_{t-2}w_{t-2}) +\\ E(w_{t-3}w_t) + E(w_{t-3}w_{t-1}) + E(w_{t-3}w_{t-2})\\ + E(w_{t-4}w_t) + E(w_{t-4}w_{t-1}) + E(w_{t-4}w_{t-2})]\\ =[0 + 0 + 0 + 1 + 0 + 0 + 0 + 0 + 0] =$$ s = t – 3 $$ E[m_{t-3}m_t] = E[(w_{t-3} + w_{t-4} + w_{t-5})(w_t + w_{t-1} + w_{t-2})]\\ = E[w_{t-3}w_t + w_{t-3}w_{t-1} + w_{t-3}w_{t-2} + w_{t-4}w_t + w_{t-4}w_{t-1} \\ + w_{t-4}w_{t-2} + w_{t-5}w_t + w_{t-5}w_{t-1} + w_{t-5}w_{t-2}]\\ = E[0+ 0 + 0 + 0 + 0 + 0 + 0 + 0 + 0]= 0 $$ Notice that s = t + 1, t + 2, … can be found in a similar manner. Also s = t - 4, t - 5,… can be found. In summary, the autocovariance function is\\[\\begin{cases} \\gamma(s,t)= \\frac{3}{9} &amp; \\text{if } s=t \\\\ \\gamma(s,t)= \\frac{2}{9} &amp; \\text{if } |s-t|=1\\\\ \\gamma(s,t)= \\frac{1}{9} &amp; \\text{if } |s-t|=2\\\\ \\gamma(s,t)= 0 &amp; \\text{if } |s-t|\\ge 3\\\\ \\end{cases}\\] Notes: - The word “lag” is used to denote the time separation between two values. For example, |s - t| = 1 denotes the lag is 1 and |s - t| = 2 denotes the lag is 2. We will use this “lag” terminology throughout this course. The autocovariance depends on the lag, but NOT individual times for the moving average example! This will be VERY, VERY important later! Autocorrelation function (ACF) In another course, the Pearson correlation coefficient was defined to be: \\[\\rho=\\frac{Cov(X,Y)}{\\sqrt{Var(X)Var(Y)}}\\] The reason the correlation coefficient is examined instead of the covariance is that it is always between –1 and 1. Note the following: - close to 1 means strong, positive linear dependence - close to –1 means strong, negative linear dependence - close to 0 means weak linear dependence. The autocorrelation is the extension of the Pearson correlation coefficient to time series analysis. The autocorrelation function (ACF) is \\[\\rho(s,t)=\\frac{\\gamma (s,t)}{\\sqrt{\\gamma (s,s)\\gamma (t,t)}}\\] where s and t denote two time points. The ACF is also between –1 and 1 and has a similar interpretation as for correlation coefficient. Notice that \\(\\gamma (t,t)\\) is the variance at time t. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
